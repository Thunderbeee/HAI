{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f399f969",
   "metadata": {
    "id": "f399f969"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bKZFV0cBQ4q_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bKZFV0cBQ4q_",
    "outputId": "1d5a7508-68d8-4707-fd07-44130668a4a4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-93b7df26abb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3b3205",
   "metadata": {
    "id": "7a3b3205"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "class allaction():\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        self.df = pd.read_csv(file) \n",
    "        # self.df = self.df.sample(frac=1, random_state=42).reset_index().drop(\"index\", axis=1)\n",
    "        self.orderId, self.taskId, self.taskTicks, self.workerId, self.workerTicks = [], [], [], [], []\n",
    "        self.ResponseId, self.Round, self.Tick = [], [], []\n",
    "    #taskId: 0~idle, 1~chop, 2~cook, 3~plate\n",
    "    #workerId: 0~chef, 1~sou-chef, 2~server\n",
    "    #           0~sou-chef, 1~server, CHANGE!!! 0~idle, 1~chef, 2~sou-chef, 3~server\n",
    "    \n",
    "    def parse(self):\n",
    "        # all id + 1, leaving 0 to be idle\n",
    "        action = self.df\n",
    "        for i in tqdm(np.arange(action.shape[0])):\n",
    "            row = action.iloc[i,:]\n",
    "            for act in [\"action1\", \"action2\", \"action3\"]:\n",
    "                # when there is no action in this act\n",
    "                if type(row[act]) != str:\n",
    "                    self.orderId.append(0)\n",
    "                    self.taskId.append(0)\n",
    "                    self.taskTicks.append(0)\n",
    "                    self.workerId.append(0)\n",
    "                    self.workerTicks.append(0)\n",
    "                else:\n",
    "                    a = ast.literal_eval(row[act])\n",
    "                    self.orderId.append(a[\"order_id\"] + 1)\n",
    "                    self.taskId.append(a[\"task_id\"] + 1)\n",
    "                    self.taskTicks.append(a[\"task_ticks\"])\n",
    "                    self.workerId.append(a[\"worker_id\"] + 1)\n",
    "                    self.workerTicks.append(a[\"worker_ticks\"])\n",
    "\n",
    "                self.ResponseId.append(row[\"ResponseId\"])\n",
    "                self.Round.append(row[\"round\"])\n",
    "                self.Tick.append(row[\"tick\"])\n",
    "                \n",
    "    def get(self):\n",
    "        self.parse()\n",
    "        d = {\n",
    "            \"ResponseId\": self.ResponseId,\n",
    "            \"round\": self.Round,\n",
    "            \"tick\": self.Tick,\n",
    "            \"orderId\": self.orderId, \n",
    "            \"taskId\": self.taskId, \n",
    "            \"taskTicks\": self.taskTicks, \n",
    "            \"workerId\": self.workerId, \n",
    "            \"workerTicks\": self.workerTicks\n",
    "        }\n",
    "        return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "NaoQqEXYlMk4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NaoQqEXYlMk4",
    "outputId": "f277c976-959e-425f-943f-41c25e331492"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866681aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "866681aa",
    "outputId": "bae8d469-d0e2-4cf4-dc34-a583bbaa0db8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195642/195642 [00:35<00:00, 5504.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th>orderId</th>\n",
       "      <th>taskId</th>\n",
       "      <th>taskTicks</th>\n",
       "      <th>workerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_09f8RCjNyCadwPv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_09f8RCjNyCadwPv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_09f8RCjNyCadwPv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_09f8RCjNyCadwPv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_09f8RCjNyCadwPv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586474</th>\n",
       "      <td>R_zffMypmlgQF5Yl3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586475</th>\n",
       "      <td>R_zffMypmlgQF5Yl3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586476</th>\n",
       "      <td>R_zffMypmlgQF5Yl3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586477</th>\n",
       "      <td>R_zffMypmlgQF5Yl3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586478</th>\n",
       "      <td>R_zffMypmlgQF5Yl3</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137505 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ResponseId  round  tick  orderId  taskId  taskTicks  workerId\n",
       "0       R_09f8RCjNyCadwPv      1     1        1       1          2         1\n",
       "1       R_09f8RCjNyCadwPv      1     1        2       1          2         2\n",
       "2       R_09f8RCjNyCadwPv      1     1        3       1          2         3\n",
       "3       R_09f8RCjNyCadwPv      1     2        0       0          0         0\n",
       "4       R_09f8RCjNyCadwPv      1     2        0       0          0         0\n",
       "...                   ...    ...   ...      ...     ...        ...       ...\n",
       "586474  R_zffMypmlgQF5Yl3      2    18        0       0          0         0\n",
       "586475  R_zffMypmlgQF5Yl3      2    18        0       0          0         0\n",
       "586476  R_zffMypmlgQF5Yl3      2    19        4       3          2         3\n",
       "586477  R_zffMypmlgQF5Yl3      2    19        0       0          0         0\n",
       "586478  R_zffMypmlgQF5Yl3      2    19        0       0          0         0\n",
       "\n",
       "[137505 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file =  \"./data/phase2/phase2_action.csv\"\n",
    "action = allaction(file).get()\n",
    "action = action[action[\"round\"] <= 2]\n",
    "action = action.drop(\"workerTicks\", axis=1)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7815c817",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "7815c817",
    "outputId": "56825c3c-5581-41c8-a7dc-d5ef625f0759",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0db963b2-bf94-4c44-9d5b-1b9d0a94afd9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>label</th>\n",
       "      <th>suggested_tip_disrupted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_10HkPUkR6o0qDFT</td>\n",
       "      <td>9</td>\n",
       "      <td>Server cooks twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_1JCkfcOwq1eNbLu</td>\n",
       "      <td>9</td>\n",
       "      <td>Make sure the server cooks twice, even if that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_1K3WThoBHDDfbk0</td>\n",
       "      <td>9</td>\n",
       "      <td>the server needs to cook twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_1M40hSm4fF4Saxv</td>\n",
       "      <td>9</td>\n",
       "      <td>Server cooks twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_1Q5tRaFyI9DwIn4</td>\n",
       "      <td>9</td>\n",
       "      <td>Make the server cook twice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>R_XoEfxfWvLu2dznr</td>\n",
       "      <td>8</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>R_2s5D6EJ0FlMyr39</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>R_2Vf01KGZrR5fscp</td>\n",
       "      <td>1</td>\n",
       "      <td>leave some chefs idle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>R_38EvwAyoLTJRsZP</td>\n",
       "      <td>8</td>\n",
       "      <td>game didn't load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>R_eVdojWlbbrNoHvj</td>\n",
       "      <td>7</td>\n",
       "      <td>only have sous chef plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0db963b2-bf94-4c44-9d5b-1b9d0a94afd9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0db963b2-bf94-4c44-9d5b-1b9d0a94afd9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0db963b2-bf94-4c44-9d5b-1b9d0a94afd9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            ResponseId  label  \\\n",
       "0    R_10HkPUkR6o0qDFT      9   \n",
       "1    R_1JCkfcOwq1eNbLu      9   \n",
       "2    R_1K3WThoBHDDfbk0      9   \n",
       "3    R_1M40hSm4fF4Saxv      9   \n",
       "4    R_1Q5tRaFyI9DwIn4      9   \n",
       "..                 ...    ...   \n",
       "285  R_XoEfxfWvLu2dznr      8   \n",
       "286  R_2s5D6EJ0FlMyr39      8   \n",
       "287  R_2Vf01KGZrR5fscp      1   \n",
       "288  R_38EvwAyoLTJRsZP      8   \n",
       "289  R_eVdojWlbbrNoHvj      7   \n",
       "\n",
       "                               suggested_tip_disrupted  \n",
       "0                                   Server cooks twice  \n",
       "1    Make sure the server cooks twice, even if that...  \n",
       "2                       the server needs to cook twice  \n",
       "3                                   Server cooks twice  \n",
       "4                           Make the server cook twice  \n",
       "..                                                 ...  \n",
       "285                                               good  \n",
       "286                                                0.5  \n",
       "287                              leave some chefs idle  \n",
       "288                                   game didn't load  \n",
       "289                          only have sous chef plate  \n",
       "\n",
       "[290 rows x 3 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label=pd.read_csv( \"label_after.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "33c38fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "33c38fa4",
    "outputId": "9b909b8e-dea4-4354-986d-134ec2cf9618",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-df036c79-0434-449f-b9cf-47395c58b1b3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th>orderId</th>\n",
       "      <th>taskId</th>\n",
       "      <th>taskTicks</th>\n",
       "      <th>workerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33427</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33428</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33429</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33430</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33431</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33432 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df036c79-0434-449f-b9cf-47395c58b1b3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-df036c79-0434-449f-b9cf-47395c58b1b3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-df036c79-0434-449f-b9cf-47395c58b1b3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              ResponseId  round  tick  orderId  taskId  taskTicks  workerId\n",
       "0      R_0HBxBV8U696D9QJ      1     1        1       1          2         1\n",
       "1      R_0HBxBV8U696D9QJ      1     1        2       1          2         2\n",
       "2      R_0HBxBV8U696D9QJ      1     1        3       1          2         3\n",
       "3      R_0HBxBV8U696D9QJ      1     2        0       0          0         0\n",
       "4      R_0HBxBV8U696D9QJ      1     2        0       0          0         0\n",
       "...                  ...    ...   ...      ...     ...        ...       ...\n",
       "33427  R_zZQIbE0LFD13yRX      2    29        0       0          0         0\n",
       "33428  R_zZQIbE0LFD13yRX      2    29        0       0          0         0\n",
       "33429  R_zZQIbE0LFD13yRX      2    30        0       0          0         0\n",
       "33430  R_zZQIbE0LFD13yRX      2    30        0       0          0         0\n",
       "33431  R_zZQIbE0LFD13yRX      2    30        0       0          0         0\n",
       "\n",
       "[33432 rows x 7 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = action.merge(label,how = \"inner\",\n",
    "            left_on=\"ResponseId\", right_on=\"ResponseId\")\n",
    "y = action[\"label\"]\n",
    "action = action.iloc[:,0:7]\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "75d6b40f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75d6b40f",
    "outputId": "bc3629cb-c975-48d8-c79a-e9506b291a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseId\n",
       "R_0HBxBV8U696D9QJ    1\n",
       "R_0SZ9OfuWvmqeMqR    5\n",
       "R_10DdLv5uPLAfpAR    2\n",
       "R_10Ggl6dEPfo9ipw    0\n",
       "R_10HkPUkR6o0qDFT    8\n",
       "                    ..\n",
       "R_yZJ03FFfe8jfazn    8\n",
       "R_ykkhkGYu1KpIM8h    0\n",
       "R_ym9gyf6T2XORxAt    0\n",
       "R_z8OxWJ4ua6nKKB3    7\n",
       "R_zZQIbE0LFD13yRX    2\n",
       "Name: label, Length: 245, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = action.merge(label,how = \"inner\",\n",
    "            left_on=\"ResponseId\", right_on=\"ResponseId\").groupby(\"ResponseId\").agg(np.mean)[\"label\"].astype(int)\n",
    "y = y-1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3f445973",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "3f445973",
    "outputId": "b7bf13b4-fafd-45a3-8a7a-7645fc9763a7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-83857a80-773f-43a1-9293-fd99532ede88\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>chop</th>\n",
       "      <th>cook</th>\n",
       "      <th>plate</th>\n",
       "      <th>idle</th>\n",
       "      <th>chef</th>\n",
       "      <th>sou-chef</th>\n",
       "      <th>server</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">R_0HBxBV8U696D9QJ</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">R_zZQIbE0LFD13yRX</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11144 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83857a80-773f-43a1-9293-fd99532ede88')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-83857a80-773f-43a1-9293-fd99532ede88 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-83857a80-773f-43a1-9293-fd99532ede88');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                              chop  cook  plate  idle  chef  sou-chef  server\n",
       "ResponseId        round tick                                                 \n",
       "R_0HBxBV8U696D9QJ 1     1        3     0      0     0     1         1       1\n",
       "                        2        0     0      0     3     0         0       0\n",
       "                        3        0     1      0     2     1         0       0\n",
       "                        4        0     1      0     2     1         0       0\n",
       "                        5        0     2      0     1     1         1       0\n",
       "...                            ...   ...    ...   ...   ...       ...     ...\n",
       "R_zZQIbE0LFD13yRX 2     26       0     0      0     3     0         0       0\n",
       "                        27       0     0      0     3     0         0       0\n",
       "                        28       0     0      0     3     0         0       0\n",
       "                        29       0     0      0     3     0         0       0\n",
       "                        30       0     0      0     3     0         0       0\n",
       "\n",
       "[11144 rows x 7 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = action.drop(\"orderId\", axis=1)\n",
    "t2 = t1.merge(pd.get_dummies(t1[\"taskId\"]), left_index=True, right_index=True).drop(\"taskId\", axis=1).rename(\n",
    "    columns={0:\"idle\", 1:\"chop\", 2:\"cook\", 3:\"plate\"})\n",
    "df = t2.merge(pd.get_dummies(t2[\"workerId\"]), left_index=True, right_index=True).drop(\"workerId\", axis=1).rename(\n",
    "    columns={0:\"idle\", 1:\"chef\", 2:\"sou-chef\", 3:\"server\"})\n",
    "df.drop(\"taskTicks\", axis=1).groupby([\"ResponseId\", \"round\", \"tick\"]).sum().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "fa6b2f25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "fa6b2f25",
    "outputId": "f4b377b1-f202-4060-caf6-2f5be2dfdba2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7d6fbc67-2518-4020-ba4a-f1de445973ea\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th>taskTicks</th>\n",
       "      <th>idle</th>\n",
       "      <th>chop</th>\n",
       "      <th>cook</th>\n",
       "      <th>plate</th>\n",
       "      <th>idle</th>\n",
       "      <th>chef</th>\n",
       "      <th>sou-chef</th>\n",
       "      <th>server</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33427</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33428</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33429</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33430</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33431</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33432 rows × 13 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d6fbc67-2518-4020-ba4a-f1de445973ea')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7d6fbc67-2518-4020-ba4a-f1de445973ea button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7d6fbc67-2518-4020-ba4a-f1de445973ea');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              ResponseId  round  tick  taskTicks  idle  chop  cook  plate  \\\n",
       "0      R_0HBxBV8U696D9QJ      1     1          2     0     1     0      0   \n",
       "1      R_0HBxBV8U696D9QJ      1     1          2     0     1     0      0   \n",
       "2      R_0HBxBV8U696D9QJ      1     1          2     0     1     0      0   \n",
       "3      R_0HBxBV8U696D9QJ      1     2          0     1     0     0      0   \n",
       "4      R_0HBxBV8U696D9QJ      1     2          0     1     0     0      0   \n",
       "...                  ...    ...   ...        ...   ...   ...   ...    ...   \n",
       "33427  R_zZQIbE0LFD13yRX      2    29          0     1     0     0      0   \n",
       "33428  R_zZQIbE0LFD13yRX      2    29          0     1     0     0      0   \n",
       "33429  R_zZQIbE0LFD13yRX      2    30          0     1     0     0      0   \n",
       "33430  R_zZQIbE0LFD13yRX      2    30          0     1     0     0      0   \n",
       "33431  R_zZQIbE0LFD13yRX      2    30          0     1     0     0      0   \n",
       "\n",
       "       idle  chef  sou-chef  server  label  \n",
       "0         0     1         0       0      1  \n",
       "1         0     0         1       0      1  \n",
       "2         0     0         0       1      1  \n",
       "3         1     0         0       0      1  \n",
       "4         1     0         0       0      1  \n",
       "...     ...   ...       ...     ...    ...  \n",
       "33427     1     0         0       0      2  \n",
       "33428     1     0         0       0      2  \n",
       "33429     1     0         0       0      2  \n",
       "33430     1     0         0       0      2  \n",
       "33431     1     0         0       0      2  \n",
       "\n",
       "[33432 rows x 13 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(pd.DataFrame(y), how=\"left\",left_on=\"ResponseId\", right_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "pUOGSwVgZ7m3",
   "metadata": {
    "id": "pUOGSwVgZ7m3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e99fe2ee",
   "metadata": {
    "id": "e99fe2ee"
   },
   "outputs": [],
   "source": [
    "a = df.drop(\"taskTicks\", axis=1)\n",
    "X = a.groupby([\"ResponseId\", \"round\", \"tick\", \"label\"]).agg(lambda x: x.iloc[0]).merge(\n",
    "    a.groupby([\"ResponseId\", \"round\", \"tick\", \"label\"]).agg(lambda x: x.iloc[1]).merge(\n",
    "        a.groupby([\"ResponseId\", \"round\", \"tick\", \"label\"]).agg(lambda x: x.iloc[2])\n",
    "    , left_index=True, right_index=True), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "CjgiIdxOas03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "CjgiIdxOas03",
    "outputId": "a2b27235-19f8-4286-fd24-d3cda3c47d3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cd0290b1-c598-4366-8837-f5111e455e69\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>idle</th>\n",
       "      <th>chop</th>\n",
       "      <th>cook</th>\n",
       "      <th>plate</th>\n",
       "      <th>idle</th>\n",
       "      <th>chef</th>\n",
       "      <th>sou-chef</th>\n",
       "      <th>server</th>\n",
       "      <th>idle_x</th>\n",
       "      <th>chop_x</th>\n",
       "      <th>...</th>\n",
       "      <th>sou-chef_x</th>\n",
       "      <th>server_x</th>\n",
       "      <th>idle_y</th>\n",
       "      <th>chop_y</th>\n",
       "      <th>cook_y</th>\n",
       "      <th>plate_y</th>\n",
       "      <th>idle_y</th>\n",
       "      <th>chef_y</th>\n",
       "      <th>sou-chef_y</th>\n",
       "      <th>server_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">R_0HBxBV8U696D9QJ</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">R_zZQIbE0LFD13yRX</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>26</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11144 rows × 24 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd0290b1-c598-4366-8837-f5111e455e69')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cd0290b1-c598-4366-8837-f5111e455e69 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cd0290b1-c598-4366-8837-f5111e455e69');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                    idle  chop  cook  plate  idle  chef  \\\n",
       "ResponseId        round tick label                                        \n",
       "R_0HBxBV8U696D9QJ 1     1    1         0     1     0      0     0     1   \n",
       "                        2    1         1     0     0      0     1     0   \n",
       "                        3    1         0     0     1      0     0     1   \n",
       "                        4    1         0     0     1      0     0     1   \n",
       "                        5    1         0     0     1      0     0     1   \n",
       "...                                  ...   ...   ...    ...   ...   ...   \n",
       "R_zZQIbE0LFD13yRX 2     26   2         1     0     0      0     1     0   \n",
       "                        27   2         1     0     0      0     1     0   \n",
       "                        28   2         1     0     0      0     1     0   \n",
       "                        29   2         1     0     0      0     1     0   \n",
       "                        30   2         1     0     0      0     1     0   \n",
       "\n",
       "                                    sou-chef  server  idle_x  chop_x  ...  \\\n",
       "ResponseId        round tick label                                    ...   \n",
       "R_0HBxBV8U696D9QJ 1     1    1             0       0       0       1  ...   \n",
       "                        2    1             0       0       1       0  ...   \n",
       "                        3    1             0       0       1       0  ...   \n",
       "                        4    1             0       0       1       0  ...   \n",
       "                        5    1             0       0       0       0  ...   \n",
       "...                                      ...     ...     ...     ...  ...   \n",
       "R_zZQIbE0LFD13yRX 2     26   2             0       0       1       0  ...   \n",
       "                        27   2             0       0       1       0  ...   \n",
       "                        28   2             0       0       1       0  ...   \n",
       "                        29   2             0       0       1       0  ...   \n",
       "                        30   2             0       0       1       0  ...   \n",
       "\n",
       "                                    sou-chef_x  server_x  idle_y  chop_y  \\\n",
       "ResponseId        round tick label                                         \n",
       "R_0HBxBV8U696D9QJ 1     1    1               1         0       0       1   \n",
       "                        2    1               0         0       1       0   \n",
       "                        3    1               0         0       1       0   \n",
       "                        4    1               0         0       1       0   \n",
       "                        5    1               1         0       1       0   \n",
       "...                                        ...       ...     ...     ...   \n",
       "R_zZQIbE0LFD13yRX 2     26   2               0         0       1       0   \n",
       "                        27   2               0         0       1       0   \n",
       "                        28   2               0         0       1       0   \n",
       "                        29   2               0         0       1       0   \n",
       "                        30   2               0         0       1       0   \n",
       "\n",
       "                                    cook_y  plate_y  idle_y  chef_y  \\\n",
       "ResponseId        round tick label                                    \n",
       "R_0HBxBV8U696D9QJ 1     1    1           0        0       0       0   \n",
       "                        2    1           0        0       1       0   \n",
       "                        3    1           0        0       1       0   \n",
       "                        4    1           0        0       1       0   \n",
       "                        5    1           0        0       1       0   \n",
       "...                                    ...      ...     ...     ...   \n",
       "R_zZQIbE0LFD13yRX 2     26   2           0        0       1       0   \n",
       "                        27   2           0        0       1       0   \n",
       "                        28   2           0        0       1       0   \n",
       "                        29   2           0        0       1       0   \n",
       "                        30   2           0        0       1       0   \n",
       "\n",
       "                                    sou-chef_y  server_y  \n",
       "ResponseId        round tick label                        \n",
       "R_0HBxBV8U696D9QJ 1     1    1               0         1  \n",
       "                        2    1               0         0  \n",
       "                        3    1               0         0  \n",
       "                        4    1               0         0  \n",
       "                        5    1               0         0  \n",
       "...                                        ...       ...  \n",
       "R_zZQIbE0LFD13yRX 2     26   2               0         0  \n",
       "                        27   2               0         0  \n",
       "                        28   2               0         0  \n",
       "                        29   2               0         0  \n",
       "                        30   2               0         0  \n",
       "\n",
       "[11144 rows x 24 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a9075719",
   "metadata": {
    "id": "a9075719"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1500e63f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1500e63f",
    "outputId": "a46fdde8-7f2d-48cb-8119-04f2f5375d0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11144/11144 [00:25<00:00, 429.55it/s] \n"
     ]
    }
   ],
   "source": [
    "# chop0, chef0, server3\n",
    "embeddings = []\n",
    "for i in tqdm(np.arange(X.shape[0])):\n",
    "    embedding = [0,0,0,0,0,0,0,0,0]\n",
    "    thisline = X.iloc[i,:]\n",
    "    \n",
    "    if thisline[\"chop\"] and thisline[\"chef\"]:\n",
    "        embedding[0] = 1\n",
    "    elif thisline[\"chop\"] and thisline[\"sou-chef\"]:\n",
    "        embedding[1] = 1\n",
    "    elif thisline[\"chop\"] and thisline[\"server\"]:\n",
    "        embedding[2] = 1 \n",
    "    elif thisline[\"cook\"] and thisline[\"chef\"]:\n",
    "        embedding[3] = 1 \n",
    "    elif thisline[\"cook\"] and thisline[\"sou-chef\"]:\n",
    "        embedding[4] = 1\n",
    "    elif thisline[\"cook\"] and thisline[\"server\"]:\n",
    "        embedding[5] = 1 \n",
    "    elif thisline[\"plate\"] and thisline[\"chef\"]:\n",
    "        embedding[6] = 1 \n",
    "    elif thisline[\"plate\"] and thisline[\"sou-chef\"]:\n",
    "        embedding[7] = 1\n",
    "    elif thisline[\"plate\"] and thisline[\"server\"]:\n",
    "        embedding[8] = 1 \n",
    "        \n",
    "    if thisline[\"chop_x\"] and thisline[\"chef_x\"]:\n",
    "        embedding[0] = 1\n",
    "    elif thisline[\"chop_x\"] and thisline[\"sou-chef_x\"]:\n",
    "        embedding[1] = 1\n",
    "    elif thisline[\"chop_x\"] and thisline[\"server_x\"]:\n",
    "        embedding[2] = 1 \n",
    "    elif thisline[\"cook_x\"] and thisline[\"chef_x\"]:\n",
    "        embedding[3] = 1 \n",
    "    elif thisline[\"cook_x\"] and thisline[\"sou-chef_x\"]:\n",
    "        embedding[4] = 1\n",
    "    elif thisline[\"cook_x\"] and thisline[\"server_x\"]:\n",
    "        embedding[5] = 1 \n",
    "    elif thisline[\"plate_x\"] and thisline[\"chef_x\"]:\n",
    "        embedding[6] = 1 \n",
    "    elif thisline[\"plate_x\"] and thisline[\"sou-chef_x\"]:\n",
    "        embedding[7] = 1\n",
    "    elif thisline[\"plate_x\"] and thisline[\"server_x\"]:\n",
    "        embedding[8] = 1         \n",
    "        \n",
    "    if thisline[\"chop_y\"] and thisline[\"chef_y\"]:\n",
    "        embedding[0] = 1\n",
    "    elif thisline[\"chop_y\"] and thisline[\"sou-chef_y\"]:\n",
    "        embedding[1] = 1\n",
    "    elif thisline[\"chop_y\"] and thisline[\"server_y\"]:\n",
    "        embedding[2] = 1 \n",
    "    elif thisline[\"cook_y\"] and thisline[\"chef_y\"]:\n",
    "        embedding[3] = 1 \n",
    "    elif thisline[\"cook_y\"] and thisline[\"sou-chef_y\"]:\n",
    "        embedding[4] = 1\n",
    "    elif thisline[\"cook_y\"] and thisline[\"server_y\"]:\n",
    "        embedding[5] = 1 \n",
    "    elif thisline[\"plate_y\"] and thisline[\"chef_y\"]:\n",
    "        embedding[6] = 1 \n",
    "    elif thisline[\"plate_y\"] and thisline[\"sou-chef_y\"]:\n",
    "        embedding[7] = 1\n",
    "    elif thisline[\"plate_y\"] and thisline[\"server_y\"]:\n",
    "        embedding[8] = 1  \n",
    "    \n",
    "    embeddings.append(embedding)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7a5229f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "7a5229f7",
    "outputId": "6bee6d16-e96e-497b-dbf7-05deb2c486a7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f60119b4-2e6a-45bc-aa81-d4159e3144c4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11143</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11144 rows × 13 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f60119b4-2e6a-45bc-aa81-d4159e3144c4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f60119b4-2e6a-45bc-aa81-d4159e3144c4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f60119b4-2e6a-45bc-aa81-d4159e3144c4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              ResponseId  round  tick  label  0  1  2  3  4  5  6  7  8\n",
       "0      R_0HBxBV8U696D9QJ      1     1      1  1  1  1  0  0  0  0  0  0\n",
       "1      R_0HBxBV8U696D9QJ      1     2      1  0  0  0  0  0  0  0  0  0\n",
       "2      R_0HBxBV8U696D9QJ      1     3      1  0  0  0  1  0  0  0  0  0\n",
       "3      R_0HBxBV8U696D9QJ      1     4      1  0  0  0  1  0  0  0  0  0\n",
       "4      R_0HBxBV8U696D9QJ      1     5      1  0  0  0  1  1  0  0  0  0\n",
       "...                  ...    ...   ...    ... .. .. .. .. .. .. .. .. ..\n",
       "11139  R_zZQIbE0LFD13yRX      2    26      2  0  0  0  0  0  0  0  0  0\n",
       "11140  R_zZQIbE0LFD13yRX      2    27      2  0  0  0  0  0  0  0  0  0\n",
       "11141  R_zZQIbE0LFD13yRX      2    28      2  0  0  0  0  0  0  0  0  0\n",
       "11142  R_zZQIbE0LFD13yRX      2    29      2  0  0  0  0  0  0  0  0  0\n",
       "11143  R_zZQIbE0LFD13yRX      2    30      2  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "[11144 rows x 13 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kkk = df.drop(\"taskTicks\", axis=1).groupby([\"ResponseId\", \"round\", \"tick\", \"label\"]).sum().iloc[:,1:]\n",
    "kkk[\"index\"] = np.arange(kkk.shape[0])\n",
    "X = kkk.merge(pd.DataFrame(np.array(embeddings)),how=\"left\", left_on=\"index\", right_index=True).drop(\n",
    "    \"chop\", axis=1).drop(\"cook\", axis=1).drop(\"plate\", axis=1).drop(\"idle\", axis=1).drop(\n",
    "    \"chef\", axis=1).drop(\"sou-chef\", axis=1).drop(\"server\", axis=1).drop(\"index\", axis=1)\n",
    "X = X.reset_index()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "uEuCdUOOcr_g",
   "metadata": {
    "id": "uEuCdUOOcr_g"
   },
   "outputs": [],
   "source": [
    "# id = X.groupby([\"ResponseId\",\"tick\").agg(lambda x: x.iloc[0])\n",
    "# id = id.sample(frac=1, random_state=42)\n",
    "# TRAIN = id.iloc[:200,:]\n",
    "# TEST = id.iloc[200:,:]\n",
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2jCd_qcqbUh9",
   "metadata": {
    "id": "2jCd_qcqbUh9"
   },
   "outputs": [],
   "source": [
    "# sns.histplot(data=TRAIN, x=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "UnSwA0cigZM2",
   "metadata": {
    "id": "UnSwA0cigZM2"
   },
   "outputs": [],
   "source": [
    "# sns.histplot(data=TEST, x=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "mrqkUFGgbj0L",
   "metadata": {
    "id": "mrqkUFGgbj0L"
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ai3OuH2ohq3R",
   "metadata": {
    "id": "ai3OuH2ohq3R"
   },
   "outputs": [],
   "source": [
    "# TRAIN[\"id\"] = TRAIN.index\n",
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "mQB4Mt2vcLZV",
   "metadata": {
    "id": "mQB4Mt2vcLZV"
   },
   "outputs": [],
   "source": [
    "# oversample = RandomOverSampler(sampling_strategy=\"not minority\")\n",
    "# jisoo, mmy = oversample.fit_resample(TRAIN.drop(\"label\", axis=1), TRAIN[\"label\"])\n",
    "# oversample2 = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "# jisoo, mmy = oversample2.fit_resample(jisoo, mmy)\n",
    "# sampled = jisoo.merge(mmy, left_index=True, right_index=True)\n",
    "# sampled = sampled.merge(TRAIN, how=\"left\", left_on=\"id\", right_on=\"id\")\n",
    "# sampled = sampled.drop(['round_y', 'tick_y', 'label_y', '0_y',\n",
    "#        '1_y', '2_y', '3_y', '4_y', '5_y', '6_y', '7_y', '8_y'], axis=1)\n",
    "# sampled = sampled.rename(columns={\n",
    "#     \"round_x\":\"round\",\n",
    "#     \"tick_x\":\"tick\",\n",
    "#     \"0_x\":\"0\",\n",
    "#     \"1_x\":\"1\",\n",
    "#     \"2_x\":\"2\",\n",
    "#     \"3_x\":\"3\",\n",
    "#     \"4_x\":\"4\",\n",
    "#     \"5_x\":\"5\",\n",
    "#     \"6_x\":\"6\",\n",
    "#     \"7_x\":\"7\",\n",
    "#     \"8_x\":\"8\",\n",
    "#     \"label_x\":\"label\",\n",
    "#     \"id\":\"ResponseId\"\n",
    "# })\n",
    "# sampled = sampled.set_index(\"ResponseId\")\n",
    "# TRAIN = sampled.iloc[:,[0,1,11,2,3,4,5,6,7,8,9,10]]\n",
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "jYInbFo2kSUY",
   "metadata": {
    "id": "jYInbFo2kSUY"
   },
   "outputs": [],
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5deEt9r8dskv",
   "metadata": {
    "id": "5deEt9r8dskv"
   },
   "outputs": [],
   "source": [
    "# after = pd.DataFrame(mmy).reset_index()\n",
    "# sns.histplot(data=after, x=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "49eIHayWFRbo",
   "metadata": {
    "id": "49eIHayWFRbo"
   },
   "outputs": [],
   "source": [
    "max_time_tick = max(X.groupby(\"ResponseId\").count()[\"round\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "nhyB0WbdlsQU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "nhyB0WbdlsQU",
    "outputId": "d5838f9a-d3a4-4c35-b49f-a2f1499f9c6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3e269428-b029-48b4-81ed-95c95d27cfeb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>round</th>\n",
       "      <th>tick</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_0HBxBV8U696D9QJ</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11139</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11142</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11143</th>\n",
       "      <td>R_zZQIbE0LFD13yRX</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11144 rows × 13 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e269428-b029-48b4-81ed-95c95d27cfeb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3e269428-b029-48b4-81ed-95c95d27cfeb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3e269428-b029-48b4-81ed-95c95d27cfeb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              ResponseId  round  tick  label  0  1  2  3  4  5  6  7  8\n",
       "0      R_0HBxBV8U696D9QJ      1     1      1  1  1  1  0  0  0  0  0  0\n",
       "1      R_0HBxBV8U696D9QJ      1     2      1  0  0  0  0  0  0  0  0  0\n",
       "2      R_0HBxBV8U696D9QJ      1     3      1  0  0  0  1  0  0  0  0  0\n",
       "3      R_0HBxBV8U696D9QJ      1     4      1  0  0  0  1  0  0  0  0  0\n",
       "4      R_0HBxBV8U696D9QJ      1     5      1  0  0  0  1  1  0  0  0  0\n",
       "...                  ...    ...   ...    ... .. .. .. .. .. .. .. .. ..\n",
       "11139  R_zZQIbE0LFD13yRX      2    26      2  0  0  0  0  0  0  0  0  0\n",
       "11140  R_zZQIbE0LFD13yRX      2    27      2  0  0  0  0  0  0  0  0  0\n",
       "11141  R_zZQIbE0LFD13yRX      2    28      2  0  0  0  0  0  0  0  0  0\n",
       "11142  R_zZQIbE0LFD13yRX      2    29      2  0  0  0  0  0  0  0  0  0\n",
       "11143  R_zZQIbE0LFD13yRX      2    30      2  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "[11144 rows x 13 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "epUK9HIfl5ad",
   "metadata": {
    "id": "epUK9HIfl5ad"
   },
   "outputs": [],
   "source": [
    "# TRAIN[\"newId\"] = np.arange(531)\n",
    "# TRAIN[\"round\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5fced6e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fced6e3",
    "outputId": "37fae560-ffdd-4de9-c43c-a7eb22942eaa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 245/245 [00:00<00:00, 370.05it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for player in tqdm(set(X[\"ResponseId\"])):\n",
    "    batch = np.array(X[X[\"ResponseId\"] == player].iloc[:,4:]).tolist()\n",
    "    padding = max_time_tick - len(batch)\n",
    "    if padding > 0  :\n",
    "        for _ in np.arange(padding):\n",
    "            batch.append([0,0,0,0,0,0,0,0,0])\n",
    "    data.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6a7c8",
   "metadata": {
    "id": "82d6a7c8"
   },
   "outputs": [],
   "source": [
    "tensor = np.array(data)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5d042c4f",
   "metadata": {
    "id": "5d042c4f"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "Coo-P0qOhAL_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Coo-P0qOhAL_",
    "outputId": "48351d52-c97c-4d5b-eff8-d9b82b1f0bcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 5, 2, 0, 8, 7, 4, 3, 6])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7bf84c3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bf84c3e",
    "outputId": "fd6bfe24-1bb3-4cb8-be38-f6882794e62a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 83, 9)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = tensor[:200], y[:200]\n",
    "X_test, y_test = tensor[200:], y[200:]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "wJiIA0k1pOH_",
   "metadata": {
    "id": "wJiIA0k1pOH_"
   },
   "outputs": [],
   "source": [
    "x_id = np.arange(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "iGlj0sd4oyM6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGlj0sd4oyM6",
    "outputId": "a5ce4769-1464-46b7-96e8-fce77649b748"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 567/567 [00:00<00:00, 19580.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(567,)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=\"not minority\")\n",
    "jisoo, mmy = oversample.fit_resample(x_id.reshape(-1, 1), y_train)\n",
    "oversample2 = RandomOverSampler(sampling_strategy=\"minority\")\n",
    "id, y_train_new = oversample2.fit_resample(jisoo, mmy)\n",
    "new = []\n",
    "for i in tqdm(id.squeeze()):\n",
    "  new.append(X_train[i].tolist())\n",
    "X_train_new =  np.array(new)\n",
    "y_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "isohtVbzonN8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "isohtVbzonN8",
    "outputId": "5c79b6f4-14b8-4ea6-ddc6-27d13c6e5dea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff1616292d0>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3cX1g_q6orOO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "3cX1g_q6orOO",
    "outputId": "8c463d98-781e-46ea-d143-602b2a097152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff2cb2ca350>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "gCYv1L-pqQ6P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "gCYv1L-pqQ6P",
    "outputId": "8825cc0a-c26b-4060-af21-be09b70ec971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff15f944f90>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oI1-HCaUYsiV",
   "metadata": {
    "id": "oI1-HCaUYsiV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e07bf56e",
   "metadata": {
    "id": "e07bf56e"
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=10, kernel_size=20, padding=\"same\", activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Conv1D(filters=8, kernel_size=15, padding=\"same\",activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Conv1D(filters=8, kernel_size=10, padding=\"same\",activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=8, kernel_size=5, padding=\"same\",activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Conv1D(filters=5, kernel_size=5, padding=\"same\",activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Conv1D(filters=5, kernel_size=5, padding=\"same\",activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Conv1D(filters=5, kernel_size=3, padding=\"same\",activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "87081f9e",
   "metadata": {
    "id": "87081f9e"
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "    n_classes = 9\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    # for dim in mlp_units:\n",
    "    x = layers.Dense(256, activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Dense(128, activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Dense(32, activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\", kernel_regularizer = \"l1\")(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b903a2a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b903a2a0",
    "outputId": "a5cb82b2-45e9-44e0-af17-b220352bafe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 83, 9)]      0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_480 (Layer  (None, 83, 9)       18          ['input_16[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention_240 (Mult  (None, 83, 9)       79881       ['layer_normalization_480[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_480[0][0]']\n",
      "                                                                                                  \n",
      " dropout_733 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_240[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_480 (TFOp  (None, 83, 9)       0           ['dropout_733[0][0]',            \n",
      " Lambda)                                                          'input_16[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_481 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_480[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2160 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_481[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2161 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2160[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2162 (Conv1D)           (None, 83, 8)        648         ['conv1d_2161[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_734 (Dropout)          (None, 83, 8)        0           ['conv1d_2162[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2163 (Conv1D)           (None, 83, 8)        328         ['dropout_734[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2164 (Conv1D)           (None, 83, 5)        205         ['conv1d_2163[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2165 (Conv1D)           (None, 83, 5)        130         ['conv1d_2164[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2166 (Conv1D)           (None, 83, 5)        80          ['conv1d_2165[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2167 (Conv1D)           (None, 83, 3)        18          ['conv1d_2166[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_735 (Dropout)          (None, 83, 3)        0           ['conv1d_2167[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2168 (Conv1D)           (None, 83, 9)        36          ['dropout_735[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_481 (TFOp  (None, 83, 9)       0           ['conv1d_2168[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_480[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_482 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_481[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_241 (Mult  (None, 83, 9)       79881       ['layer_normalization_482[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_482[0][0]']\n",
      "                                                                                                  \n",
      " dropout_736 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_241[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_482 (TFOp  (None, 83, 9)       0           ['dropout_736[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_481[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_483 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_482[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2169 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_483[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2170 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2169[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2171 (Conv1D)           (None, 83, 8)        648         ['conv1d_2170[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_737 (Dropout)          (None, 83, 8)        0           ['conv1d_2171[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2172 (Conv1D)           (None, 83, 8)        328         ['dropout_737[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2173 (Conv1D)           (None, 83, 5)        205         ['conv1d_2172[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2174 (Conv1D)           (None, 83, 5)        130         ['conv1d_2173[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2175 (Conv1D)           (None, 83, 5)        80          ['conv1d_2174[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2176 (Conv1D)           (None, 83, 3)        18          ['conv1d_2175[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_738 (Dropout)          (None, 83, 3)        0           ['conv1d_2176[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2177 (Conv1D)           (None, 83, 9)        36          ['dropout_738[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_483 (TFOp  (None, 83, 9)       0           ['conv1d_2177[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_482[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_484 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_483[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_242 (Mult  (None, 83, 9)       79881       ['layer_normalization_484[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_484[0][0]']\n",
      "                                                                                                  \n",
      " dropout_739 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_242[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_484 (TFOp  (None, 83, 9)       0           ['dropout_739[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_483[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_485 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_484[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2178 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_485[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2179 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2178[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2180 (Conv1D)           (None, 83, 8)        648         ['conv1d_2179[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_740 (Dropout)          (None, 83, 8)        0           ['conv1d_2180[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2181 (Conv1D)           (None, 83, 8)        328         ['dropout_740[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2182 (Conv1D)           (None, 83, 5)        205         ['conv1d_2181[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2183 (Conv1D)           (None, 83, 5)        130         ['conv1d_2182[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2184 (Conv1D)           (None, 83, 5)        80          ['conv1d_2183[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2185 (Conv1D)           (None, 83, 3)        18          ['conv1d_2184[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_741 (Dropout)          (None, 83, 3)        0           ['conv1d_2185[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2186 (Conv1D)           (None, 83, 9)        36          ['dropout_741[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_485 (TFOp  (None, 83, 9)       0           ['conv1d_2186[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_484[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_486 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_485[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_243 (Mult  (None, 83, 9)       79881       ['layer_normalization_486[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_486[0][0]']\n",
      "                                                                                                  \n",
      " dropout_742 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_243[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_486 (TFOp  (None, 83, 9)       0           ['dropout_742[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_485[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_487 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_486[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2187 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_487[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2188 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2187[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2189 (Conv1D)           (None, 83, 8)        648         ['conv1d_2188[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_743 (Dropout)          (None, 83, 8)        0           ['conv1d_2189[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2190 (Conv1D)           (None, 83, 8)        328         ['dropout_743[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2191 (Conv1D)           (None, 83, 5)        205         ['conv1d_2190[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2192 (Conv1D)           (None, 83, 5)        130         ['conv1d_2191[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2193 (Conv1D)           (None, 83, 5)        80          ['conv1d_2192[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2194 (Conv1D)           (None, 83, 3)        18          ['conv1d_2193[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_744 (Dropout)          (None, 83, 3)        0           ['conv1d_2194[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2195 (Conv1D)           (None, 83, 9)        36          ['dropout_744[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_487 (TFOp  (None, 83, 9)       0           ['conv1d_2195[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_486[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_488 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_487[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_244 (Mult  (None, 83, 9)       79881       ['layer_normalization_488[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_488[0][0]']\n",
      "                                                                                                  \n",
      " dropout_745 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_244[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_488 (TFOp  (None, 83, 9)       0           ['dropout_745[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_487[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_489 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_488[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2196 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_489[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2197 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2196[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2198 (Conv1D)           (None, 83, 8)        648         ['conv1d_2197[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_746 (Dropout)          (None, 83, 8)        0           ['conv1d_2198[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2199 (Conv1D)           (None, 83, 8)        328         ['dropout_746[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2200 (Conv1D)           (None, 83, 5)        205         ['conv1d_2199[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2201 (Conv1D)           (None, 83, 5)        130         ['conv1d_2200[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2202 (Conv1D)           (None, 83, 5)        80          ['conv1d_2201[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2203 (Conv1D)           (None, 83, 3)        18          ['conv1d_2202[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_747 (Dropout)          (None, 83, 3)        0           ['conv1d_2203[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2204 (Conv1D)           (None, 83, 9)        36          ['dropout_747[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_489 (TFOp  (None, 83, 9)       0           ['conv1d_2204[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_488[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_490 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_489[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_245 (Mult  (None, 83, 9)       79881       ['layer_normalization_490[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_490[0][0]']\n",
      "                                                                                                  \n",
      " dropout_748 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_245[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_490 (TFOp  (None, 83, 9)       0           ['dropout_748[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_489[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_491 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_490[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2205 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_491[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2206 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2205[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2207 (Conv1D)           (None, 83, 8)        648         ['conv1d_2206[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_749 (Dropout)          (None, 83, 8)        0           ['conv1d_2207[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2208 (Conv1D)           (None, 83, 8)        328         ['dropout_749[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2209 (Conv1D)           (None, 83, 5)        205         ['conv1d_2208[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2210 (Conv1D)           (None, 83, 5)        130         ['conv1d_2209[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2211 (Conv1D)           (None, 83, 5)        80          ['conv1d_2210[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2212 (Conv1D)           (None, 83, 3)        18          ['conv1d_2211[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_750 (Dropout)          (None, 83, 3)        0           ['conv1d_2212[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2213 (Conv1D)           (None, 83, 9)        36          ['dropout_750[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_491 (TFOp  (None, 83, 9)       0           ['conv1d_2213[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_490[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_492 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_491[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_246 (Mult  (None, 83, 9)       79881       ['layer_normalization_492[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_492[0][0]']\n",
      "                                                                                                  \n",
      " dropout_751 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_246[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_492 (TFOp  (None, 83, 9)       0           ['dropout_751[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_491[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_493 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_492[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2214 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_493[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2215 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2214[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2216 (Conv1D)           (None, 83, 8)        648         ['conv1d_2215[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_752 (Dropout)          (None, 83, 8)        0           ['conv1d_2216[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2217 (Conv1D)           (None, 83, 8)        328         ['dropout_752[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2218 (Conv1D)           (None, 83, 5)        205         ['conv1d_2217[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2219 (Conv1D)           (None, 83, 5)        130         ['conv1d_2218[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2220 (Conv1D)           (None, 83, 5)        80          ['conv1d_2219[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2221 (Conv1D)           (None, 83, 3)        18          ['conv1d_2220[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_753 (Dropout)          (None, 83, 3)        0           ['conv1d_2221[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2222 (Conv1D)           (None, 83, 9)        36          ['dropout_753[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_493 (TFOp  (None, 83, 9)       0           ['conv1d_2222[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_492[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_494 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_493[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_247 (Mult  (None, 83, 9)       79881       ['layer_normalization_494[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_494[0][0]']\n",
      "                                                                                                  \n",
      " dropout_754 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_247[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_494 (TFOp  (None, 83, 9)       0           ['dropout_754[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_493[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_495 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_494[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2223 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_495[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2224 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2223[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2225 (Conv1D)           (None, 83, 8)        648         ['conv1d_2224[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_755 (Dropout)          (None, 83, 8)        0           ['conv1d_2225[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2226 (Conv1D)           (None, 83, 8)        328         ['dropout_755[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2227 (Conv1D)           (None, 83, 5)        205         ['conv1d_2226[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2228 (Conv1D)           (None, 83, 5)        130         ['conv1d_2227[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2229 (Conv1D)           (None, 83, 5)        80          ['conv1d_2228[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2230 (Conv1D)           (None, 83, 3)        18          ['conv1d_2229[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_756 (Dropout)          (None, 83, 3)        0           ['conv1d_2230[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2231 (Conv1D)           (None, 83, 9)        36          ['dropout_756[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_495 (TFOp  (None, 83, 9)       0           ['conv1d_2231[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_494[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_496 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_495[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_248 (Mult  (None, 83, 9)       79881       ['layer_normalization_496[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_496[0][0]']\n",
      "                                                                                                  \n",
      " dropout_757 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_248[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_496 (TFOp  (None, 83, 9)       0           ['dropout_757[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_495[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_497 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_496[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2232 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_497[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2233 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2232[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2234 (Conv1D)           (None, 83, 8)        648         ['conv1d_2233[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_758 (Dropout)          (None, 83, 8)        0           ['conv1d_2234[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2235 (Conv1D)           (None, 83, 8)        328         ['dropout_758[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2236 (Conv1D)           (None, 83, 5)        205         ['conv1d_2235[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2237 (Conv1D)           (None, 83, 5)        130         ['conv1d_2236[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2238 (Conv1D)           (None, 83, 5)        80          ['conv1d_2237[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2239 (Conv1D)           (None, 83, 3)        18          ['conv1d_2238[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_759 (Dropout)          (None, 83, 3)        0           ['conv1d_2239[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2240 (Conv1D)           (None, 83, 9)        36          ['dropout_759[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_497 (TFOp  (None, 83, 9)       0           ['conv1d_2240[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_496[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_498 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_497[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_249 (Mult  (None, 83, 9)       79881       ['layer_normalization_498[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_498[0][0]']\n",
      "                                                                                                  \n",
      " dropout_760 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_249[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_498 (TFOp  (None, 83, 9)       0           ['dropout_760[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_497[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_499 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_498[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2241 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_499[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2242 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2241[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2243 (Conv1D)           (None, 83, 8)        648         ['conv1d_2242[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_761 (Dropout)          (None, 83, 8)        0           ['conv1d_2243[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2244 (Conv1D)           (None, 83, 8)        328         ['dropout_761[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2245 (Conv1D)           (None, 83, 5)        205         ['conv1d_2244[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2246 (Conv1D)           (None, 83, 5)        130         ['conv1d_2245[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2247 (Conv1D)           (None, 83, 5)        80          ['conv1d_2246[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2248 (Conv1D)           (None, 83, 3)        18          ['conv1d_2247[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_762 (Dropout)          (None, 83, 3)        0           ['conv1d_2248[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2249 (Conv1D)           (None, 83, 9)        36          ['dropout_762[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_499 (TFOp  (None, 83, 9)       0           ['conv1d_2249[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_498[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_500 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_499[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_250 (Mult  (None, 83, 9)       79881       ['layer_normalization_500[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_500[0][0]']\n",
      "                                                                                                  \n",
      " dropout_763 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_250[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_500 (TFOp  (None, 83, 9)       0           ['dropout_763[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_499[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_501 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_500[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2250 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_501[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2251 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2250[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2252 (Conv1D)           (None, 83, 8)        648         ['conv1d_2251[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_764 (Dropout)          (None, 83, 8)        0           ['conv1d_2252[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2253 (Conv1D)           (None, 83, 8)        328         ['dropout_764[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2254 (Conv1D)           (None, 83, 5)        205         ['conv1d_2253[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2255 (Conv1D)           (None, 83, 5)        130         ['conv1d_2254[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2256 (Conv1D)           (None, 83, 5)        80          ['conv1d_2255[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2257 (Conv1D)           (None, 83, 3)        18          ['conv1d_2256[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_765 (Dropout)          (None, 83, 3)        0           ['conv1d_2257[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2258 (Conv1D)           (None, 83, 9)        36          ['dropout_765[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_501 (TFOp  (None, 83, 9)       0           ['conv1d_2258[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_500[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_502 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_501[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_251 (Mult  (None, 83, 9)       79881       ['layer_normalization_502[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_502[0][0]']\n",
      "                                                                                                  \n",
      " dropout_766 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_251[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_502 (TFOp  (None, 83, 9)       0           ['dropout_766[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_501[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_503 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_502[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2259 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_503[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2260 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2259[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2261 (Conv1D)           (None, 83, 8)        648         ['conv1d_2260[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_767 (Dropout)          (None, 83, 8)        0           ['conv1d_2261[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2262 (Conv1D)           (None, 83, 8)        328         ['dropout_767[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2263 (Conv1D)           (None, 83, 5)        205         ['conv1d_2262[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2264 (Conv1D)           (None, 83, 5)        130         ['conv1d_2263[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2265 (Conv1D)           (None, 83, 5)        80          ['conv1d_2264[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2266 (Conv1D)           (None, 83, 3)        18          ['conv1d_2265[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_768 (Dropout)          (None, 83, 3)        0           ['conv1d_2266[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2267 (Conv1D)           (None, 83, 9)        36          ['dropout_768[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_503 (TFOp  (None, 83, 9)       0           ['conv1d_2267[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_502[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_504 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_503[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_252 (Mult  (None, 83, 9)       79881       ['layer_normalization_504[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_504[0][0]']\n",
      "                                                                                                  \n",
      " dropout_769 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_252[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_504 (TFOp  (None, 83, 9)       0           ['dropout_769[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_503[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_505 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_504[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2268 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_505[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2269 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2268[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2270 (Conv1D)           (None, 83, 8)        648         ['conv1d_2269[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_770 (Dropout)          (None, 83, 8)        0           ['conv1d_2270[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2271 (Conv1D)           (None, 83, 8)        328         ['dropout_770[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2272 (Conv1D)           (None, 83, 5)        205         ['conv1d_2271[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2273 (Conv1D)           (None, 83, 5)        130         ['conv1d_2272[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2274 (Conv1D)           (None, 83, 5)        80          ['conv1d_2273[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2275 (Conv1D)           (None, 83, 3)        18          ['conv1d_2274[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_771 (Dropout)          (None, 83, 3)        0           ['conv1d_2275[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2276 (Conv1D)           (None, 83, 9)        36          ['dropout_771[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_505 (TFOp  (None, 83, 9)       0           ['conv1d_2276[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_504[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_506 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_505[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_253 (Mult  (None, 83, 9)       79881       ['layer_normalization_506[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_506[0][0]']\n",
      "                                                                                                  \n",
      " dropout_772 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_253[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_506 (TFOp  (None, 83, 9)       0           ['dropout_772[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_505[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_507 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_506[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2277 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_507[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2278 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2277[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2279 (Conv1D)           (None, 83, 8)        648         ['conv1d_2278[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_773 (Dropout)          (None, 83, 8)        0           ['conv1d_2279[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2280 (Conv1D)           (None, 83, 8)        328         ['dropout_773[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2281 (Conv1D)           (None, 83, 5)        205         ['conv1d_2280[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2282 (Conv1D)           (None, 83, 5)        130         ['conv1d_2281[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2283 (Conv1D)           (None, 83, 5)        80          ['conv1d_2282[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2284 (Conv1D)           (None, 83, 3)        18          ['conv1d_2283[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_774 (Dropout)          (None, 83, 3)        0           ['conv1d_2284[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2285 (Conv1D)           (None, 83, 9)        36          ['dropout_774[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_507 (TFOp  (None, 83, 9)       0           ['conv1d_2285[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_506[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_508 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_507[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_254 (Mult  (None, 83, 9)       79881       ['layer_normalization_508[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_508[0][0]']\n",
      "                                                                                                  \n",
      " dropout_775 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_254[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_508 (TFOp  (None, 83, 9)       0           ['dropout_775[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_507[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_509 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_508[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2286 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_509[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2287 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2286[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2288 (Conv1D)           (None, 83, 8)        648         ['conv1d_2287[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_776 (Dropout)          (None, 83, 8)        0           ['conv1d_2288[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2289 (Conv1D)           (None, 83, 8)        328         ['dropout_776[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2290 (Conv1D)           (None, 83, 5)        205         ['conv1d_2289[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2291 (Conv1D)           (None, 83, 5)        130         ['conv1d_2290[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2292 (Conv1D)           (None, 83, 5)        80          ['conv1d_2291[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2293 (Conv1D)           (None, 83, 3)        18          ['conv1d_2292[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_777 (Dropout)          (None, 83, 3)        0           ['conv1d_2293[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2294 (Conv1D)           (None, 83, 9)        36          ['dropout_777[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_509 (TFOp  (None, 83, 9)       0           ['conv1d_2294[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_508[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_510 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_509[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " multi_head_attention_255 (Mult  (None, 83, 9)       79881       ['layer_normalization_510[0][0]',\n",
      " iHeadAttention)                                                  'layer_normalization_510[0][0]']\n",
      "                                                                                                  \n",
      " dropout_778 (Dropout)          (None, 83, 9)        0           ['multi_head_attention_255[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_510 (TFOp  (None, 83, 9)       0           ['dropout_778[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_509[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_511 (Layer  (None, 83, 9)       18          ['tf.__operators__.add_510[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " conv1d_2295 (Conv1D)           (None, 83, 10)       1810        ['layer_normalization_511[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_2296 (Conv1D)           (None, 83, 8)        1208        ['conv1d_2295[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2297 (Conv1D)           (None, 83, 8)        648         ['conv1d_2296[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_779 (Dropout)          (None, 83, 8)        0           ['conv1d_2297[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2298 (Conv1D)           (None, 83, 8)        328         ['dropout_779[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2299 (Conv1D)           (None, 83, 5)        205         ['conv1d_2298[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2300 (Conv1D)           (None, 83, 5)        130         ['conv1d_2299[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2301 (Conv1D)           (None, 83, 5)        80          ['conv1d_2300[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2302 (Conv1D)           (None, 83, 3)        18          ['conv1d_2301[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_780 (Dropout)          (None, 83, 3)        0           ['conv1d_2302[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2303 (Conv1D)           (None, 83, 9)        36          ['dropout_780[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_511 (TFOp  (None, 83, 9)       0           ['conv1d_2303[0][0]',            \n",
      " Lambda)                                                          'tf.__operators__.add_510[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 83)          0           ['tf.__operators__.add_511[0][0]'\n",
      " lobalAveragePooling1D)                                          ]                                \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 256)          21504       ['global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          32896       ['dense_93[0][0]']               \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 64)           8256        ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 32)           2080        ['dense_95[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 16)           528         ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 9)            153         ['dense_97[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,415,497\n",
      "Trainable params: 1,415,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1500\n",
      "25/25 [==============================] - 34s 341ms/step - loss: 108.6502 - accuracy: 0.0985 - val_loss: 108.4752 - val_accuracy: 0.2222\n",
      "Epoch 2/1500\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 108.3132 - accuracy: 0.1187 - val_loss: 108.1429 - val_accuracy: 0.0936\n",
      "Epoch 3/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 107.9781 - accuracy: 0.1162 - val_loss: 107.8109 - val_accuracy: 0.0819\n",
      "Epoch 4/1500\n",
      "25/25 [==============================] - 3s 137ms/step - loss: 107.6441 - accuracy: 0.1061 - val_loss: 107.4789 - val_accuracy: 0.0702\n",
      "Epoch 5/1500\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 107.3095 - accuracy: 0.1061 - val_loss: 107.1463 - val_accuracy: 0.0702\n",
      "Epoch 6/1500\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 106.9758 - accuracy: 0.1136 - val_loss: 106.8162 - val_accuracy: 0.0819\n",
      "Epoch 7/1500\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 106.6431 - accuracy: 0.1111 - val_loss: 106.4908 - val_accuracy: 0.0877\n",
      "Epoch 8/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 106.3091 - accuracy: 0.1162 - val_loss: 106.1779 - val_accuracy: 0.1053\n",
      "Epoch 9/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 105.9726 - accuracy: 0.1313 - val_loss: 105.8726 - val_accuracy: 0.0994\n",
      "Epoch 10/1500\n",
      "25/25 [==============================] - 4s 147ms/step - loss: 105.6388 - accuracy: 0.1212 - val_loss: 105.5824 - val_accuracy: 0.0351\n",
      "Epoch 11/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 105.3012 - accuracy: 0.1263 - val_loss: 105.3103 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1500\n",
      "25/25 [==============================] - 4s 146ms/step - loss: 104.9634 - accuracy: 0.1566 - val_loss: 105.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1500\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 104.6200 - accuracy: 0.1591 - val_loss: 104.6501 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 104.2728 - accuracy: 0.1591 - val_loss: 104.3918 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 103.9361 - accuracy: 0.1692 - val_loss: 104.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 103.6026 - accuracy: 0.1641 - val_loss: 103.7628 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 103.2758 - accuracy: 0.1667 - val_loss: 103.4429 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1500\n",
      "25/25 [==============================] - 3s 141ms/step - loss: 102.9360 - accuracy: 0.1616 - val_loss: 103.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1500\n",
      "25/25 [==============================] - 4s 149ms/step - loss: 102.6200 - accuracy: 0.1742 - val_loss: 102.7994 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 102.3249 - accuracy: 0.1641 - val_loss: 102.4098 - val_accuracy: 0.0058\n",
      "Epoch 21/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 102.0031 - accuracy: 0.1692 - val_loss: 102.1451 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 101.6691 - accuracy: 0.1667 - val_loss: 101.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 101.3481 - accuracy: 0.1793 - val_loss: 101.4716 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 101.0430 - accuracy: 0.1793 - val_loss: 101.2449 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 100.7274 - accuracy: 0.1616 - val_loss: 100.8931 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 100.4134 - accuracy: 0.1742 - val_loss: 100.5843 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 100.1059 - accuracy: 0.1818 - val_loss: 100.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1500\n",
      "25/25 [==============================] - 3s 138ms/step - loss: 99.8057 - accuracy: 0.1641 - val_loss: 99.9839 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1500\n",
      "25/25 [==============================] - 4s 149ms/step - loss: 99.4801 - accuracy: 0.1818 - val_loss: 99.6301 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1500\n",
      "25/25 [==============================] - 3s 139ms/step - loss: 99.1707 - accuracy: 0.1843 - val_loss: 99.3318 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 98.8681 - accuracy: 0.2045 - val_loss: 99.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 98.5619 - accuracy: 0.2222 - val_loss: 98.7577 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 98.2851 - accuracy: 0.2374 - val_loss: 98.5235 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 97.9638 - accuracy: 0.2298 - val_loss: 98.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 97.6539 - accuracy: 0.2475 - val_loss: 97.9461 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 97.3410 - accuracy: 0.2576 - val_loss: 97.6674 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 97.0398 - accuracy: 0.2677 - val_loss: 97.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 96.7507 - accuracy: 0.2702 - val_loss: 97.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 96.4492 - accuracy: 0.2828 - val_loss: 97.0021 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 96.1328 - accuracy: 0.2753 - val_loss: 96.5859 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 95.8609 - accuracy: 0.2753 - val_loss: 96.6096 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 95.5288 - accuracy: 0.3005 - val_loss: 96.3774 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 95.2322 - accuracy: 0.2929 - val_loss: 96.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 94.9560 - accuracy: 0.2929 - val_loss: 95.8014 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 94.9079 - accuracy: 0.2348 - val_loss: 95.3846 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 94.5312 - accuracy: 0.2702 - val_loss: 95.4769 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1500\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 94.2578 - accuracy: 0.2551 - val_loss: 95.0490 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1500\n",
      "25/25 [==============================] - 4s 152ms/step - loss: 93.9386 - accuracy: 0.2702 - val_loss: 94.8556 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1500\n",
      "25/25 [==============================] - 4s 153ms/step - loss: 93.6200 - accuracy: 0.2753 - val_loss: 94.5055 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1500\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 93.3282 - accuracy: 0.2778 - val_loss: 94.2252 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 93.2342 - accuracy: 0.1894 - val_loss: 93.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 92.9337 - accuracy: 0.1894 - val_loss: 93.8002 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 92.6530 - accuracy: 0.2121 - val_loss: 93.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 92.3704 - accuracy: 0.2172 - val_loss: 93.1316 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1500\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 92.1045 - accuracy: 0.2096 - val_loss: 92.7145 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 91.8295 - accuracy: 0.2146 - val_loss: 92.5218 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 91.5742 - accuracy: 0.2096 - val_loss: 92.2988 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1500\n",
      "25/25 [==============================] - 3s 141ms/step - loss: 91.2955 - accuracy: 0.2146 - val_loss: 91.8767 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 91.0292 - accuracy: 0.2146 - val_loss: 91.6525 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1500\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 90.7613 - accuracy: 0.2121 - val_loss: 91.5467 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1500\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 90.5024 - accuracy: 0.2197 - val_loss: 91.0982 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1500\n",
      "25/25 [==============================] - 4s 149ms/step - loss: 90.3559 - accuracy: 0.1742 - val_loss: 91.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1500\n",
      "25/25 [==============================] - 3s 140ms/step - loss: 90.1101 - accuracy: 0.1540 - val_loss: 90.9799 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/1500\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 89.8438 - accuracy: 0.1540 - val_loss: 90.6953 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 89.5783 - accuracy: 0.1566 - val_loss: 90.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 89.3131 - accuracy: 0.1566 - val_loss: 90.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 89.0552 - accuracy: 0.1566 - val_loss: 89.8519 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 88.7968 - accuracy: 0.1566 - val_loss: 89.5792 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1500\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 88.5313 - accuracy: 0.1566 - val_loss: 89.3220 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1500\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 88.2744 - accuracy: 0.1566 - val_loss: 89.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1500\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 88.0135 - accuracy: 0.1566 - val_loss: 88.7553 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1500\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 87.7545 - accuracy: 0.1566 - val_loss: 88.5433 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 87.4971 - accuracy: 0.1566 - val_loss: 88.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 87.2347 - accuracy: 0.1566 - val_loss: 87.9996 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 86.9783 - accuracy: 0.1566 - val_loss: 87.7208 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 86.7217 - accuracy: 0.1566 - val_loss: 87.4606 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 86.4642 - accuracy: 0.1566 - val_loss: 87.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 86.2030 - accuracy: 0.1591 - val_loss: 86.8108 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/1500\n",
      "25/25 [==============================] - 4s 151ms/step - loss: 85.9473 - accuracy: 0.1591 - val_loss: 86.5665 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 85.6845 - accuracy: 0.1591 - val_loss: 86.3758 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/1500\n",
      "25/25 [==============================] - 4s 144ms/step - loss: 85.4326 - accuracy: 0.1591 - val_loss: 86.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 85.1724 - accuracy: 0.1591 - val_loss: 85.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 84.9165 - accuracy: 0.1566 - val_loss: 85.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 84.6549 - accuracy: 0.1616 - val_loss: 85.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/1500\n",
      "25/25 [==============================] - 4s 149ms/step - loss: 84.4067 - accuracy: 0.1591 - val_loss: 84.9728 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 84.1466 - accuracy: 0.1591 - val_loss: 84.8034 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 83.9004 - accuracy: 0.1591 - val_loss: 84.5934 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 83.6351 - accuracy: 0.1566 - val_loss: 84.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 83.3859 - accuracy: 0.1591 - val_loss: 83.9398 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/1500\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 83.1331 - accuracy: 0.1566 - val_loss: 83.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 82.8738 - accuracy: 0.1591 - val_loss: 83.4849 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/1500\n",
      "25/25 [==============================] - 4s 149ms/step - loss: 82.6191 - accuracy: 0.1591 - val_loss: 83.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 82.3610 - accuracy: 0.1591 - val_loss: 82.8980 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 82.1087 - accuracy: 0.1591 - val_loss: 82.6410 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 81.8624 - accuracy: 0.1566 - val_loss: 82.4233 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 81.6104 - accuracy: 0.1439 - val_loss: 82.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 81.3567 - accuracy: 0.1591 - val_loss: 81.9770 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/1500\n",
      "25/25 [==============================] - 4s 141ms/step - loss: 81.1013 - accuracy: 0.1566 - val_loss: 81.8029 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/1500\n",
      "25/25 [==============================] - 4s 145ms/step - loss: 80.8498 - accuracy: 0.1591 - val_loss: 81.3837 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 80.5937 - accuracy: 0.1591 - val_loss: 81.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 80.3429 - accuracy: 0.1515 - val_loss: 80.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 80.0864 - accuracy: 0.1591 - val_loss: 80.6945 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 79.8407 - accuracy: 0.1515 - val_loss: 80.4474 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/1500\n",
      "25/25 [==============================] - 4s 150ms/step - loss: 79.6006 - accuracy: 0.1591 - val_loss: 80.2180 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 79.3392 - accuracy: 0.1591 - val_loss: 79.9250 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 79.0929 - accuracy: 0.1616 - val_loss: 79.7161 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/1500\n",
      "25/25 [==============================] - 4s 143ms/step - loss: 78.8381 - accuracy: 0.1591 - val_loss: 79.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 78.5783 - accuracy: 0.1616 - val_loss: 79.1663 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/1500\n",
      "25/25 [==============================] - 4s 154ms/step - loss: 78.3226 - accuracy: 0.1692 - val_loss: 79.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 78.0785 - accuracy: 0.1667 - val_loss: 78.7065 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/1500\n",
      "25/25 [==============================] - 4s 142ms/step - loss: 77.8269 - accuracy: 0.1818 - val_loss: 78.4868 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/1500\n",
      " 4/25 [===>..........................] - ETA: 2s - loss: 77.6438 - accuracy: 0.2500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-38acc210cbff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#callbacks=callbacks,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=128,\n",
    "    num_heads=16,\n",
    "    ff_dim=3,\n",
    "    num_transformer_blocks=16,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.35,\n",
    "    dropout=0.25,\n",
    "    # n_classes = 10\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=1000, restore_best_weights=True)]\n",
    "\n",
    "curve = model.fit(\n",
    "    X_train_new,\n",
    "    y_train_new,\n",
    "    validation_split=0.3,\n",
    "    epochs=1500,\n",
    "    batch_size=16,\n",
    "    #callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caaf7fc",
   "metadata": {
    "id": "1caaf7fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80531b8",
   "metadata": {
    "id": "e80531b8"
   },
   "outputs": [],
   "source": [
    "def extract(arr):\n",
    "  out = []\n",
    "  for weights in arr:\n",
    "    max_weights = np.argmax(weights)\n",
    "    out.append(max_weights)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890bf55d",
   "metadata": {
    "id": "890bf55d"
   },
   "outputs": [],
   "source": [
    "sum(extract(model.predict(X_test)) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea8daa",
   "metadata": {
    "id": "46ea8daa"
   },
   "outputs": [],
   "source": [
    "y_pred = np.array(extract(model.predict(X_test))) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ryb3vk_yNtUI",
   "metadata": {
    "id": "Ryb3vk_yNtUI"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NuPGXIr7N8wb",
   "metadata": {
    "id": "NuPGXIr7N8wb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = y_pred\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "im = plt.imshow(matrix)\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rdLCEcyy1R-p",
   "metadata": {
    "id": "rdLCEcyy1R-p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0_QFfeHhOBuw",
   "metadata": {
    "id": "0_QFfeHhOBuw"
   },
   "outputs": [],
   "source": [
    "plt.plot(curve.history['accuracy'])\n",
    "plt.plot(curve.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(curve.history['loss'])\n",
    "plt.plot(curve.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sequence.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
